# -*- coding: utf-8 -*-
"""EV.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LVajAYsA7ZMkmIaktYUOVtV41foKziVs

***Importing Libraries for Prject***
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Lasso
from sklearn import metrics

"""**Interpretation: **  

1)Pandas is a game-changer for data science and analytics, particularly if you came to Python because you were searching for something more powerful than Excel and VBA.

2)Matplotlib provides various method to Visualize data in more effective way. Matplotlib allows to quickly make line graphs, pie charts, histograms, and other professional grade figures

3)Seaborn helps to visualize the statistical relationships, To understand how variables in a dataset are related to one another and how that relationship is dependent on other variables, we perform statistical analysis.

4)NumPy (short for Numerical Python) provides an efficient interface to store and operate on dense data buffers. In some ways, NumPy arrays are like Python's built-in list type, but NumPy arrays provide much more efficient storage and data operations as the arrays grow larger in size.

5)Scikit-learn provides a uniform set of high-level APIs for building ML pipelines or workflows. You use a Scikit-learn ML Pipeline to pass the data through transformers to extract the features and an estimator to produce the model, and then evaluate predictions to measure the accuracy of the model.

**Importhing CSV file of Electronic Vehicle**
"""

df = pd.read_csv('EVDatabase.csv',encoding='cp1252')

"""**Interpretation:**
Read the csv file using Pandas file
Windows-1252 or CP-1252 (code page 1252) is a single-byte character encoding of the Latin alphabet,

**Displaying Dataset**
"""

df

"""**Interpretation:**
Data Set is denoated from Data Frame in Data Science

**Displaying Dataset Information**
"""

df.info()

"""**Interpretation:**
So, now we can see how the data looks like. It is a standard relational database kind of data, having rows and columns.
"""

df.dtypes

"""**Interpretation:** Dtypes is used to see the data type of given variable or column

**Replacing Currency sign and changing Datatypes**
"""

df['Efficiency']=df['Efficiency'].astype(str)
Efficiency=[]
for item in df['Efficiency']:
    Efficiency+=[int(item.replace(' Wh/km',''))]
df['Efficiency']=Efficiency

df['Range']=df['Range'].astype(str)
Range=[]
for item in df['Range']:
    Range+=[int(item.replace(' km',''))]
df['Range']=Range

df['FastChargeSpeed']=df['FastChargeSpeed'].astype(str)
FastChargeSpeed=[]
for item in df['FastChargeSpeed']:
    FastChargeSpeed+=[int(item.replace(' km/h','').replace('-','0'))]
df['FastChargeSpeed']=FastChargeSpeed

df['TopSpeed']=df['TopSpeed'].astype(str)
TopSpeed=[]
for item in df['TopSpeed']:
    TopSpeed+=[int(item.replace(' km/h',''))]
df['TopSpeed']=TopSpeed

df['Acceleration']=df['Acceleration'].astype(str)
Acceleration=[]
for item in df['Acceleration']:
    Acceleration+=[float(item.replace(' sec',''))]
df['Acceleration']=Acceleration

df['PriceinGermany']=df['PriceinGermany'].astype(str)
PriceinGermany=[]
for item in df['PriceinGermany']:
    PriceinGermany+=[item.replace('€','').replace(',','')]
df['PriceinGermany']= list(map(float,PriceinGermany))

df['Subtitle']=df['Subtitle'].astype(str)
Subtitle=[]
for item in df['Subtitle']:
    Subtitle+=[item.replace('Battery Electric Vehicle | ','').replace(' kWh','').replace('      ','')]
df['Subtitle']=Subtitle

df['PriceinIndia']=df['PriceinIndia'].astype(str)
PriceinIndia=[]
for item in df['PriceinIndia']:
    PriceinIndia+=[item.replace('?','').replace(',','')]
df['PriceinIndia']=list(map(float,PriceinIndia))

df['PriceinUK']=df['PriceinUK'].astype(str)
PriceinUK=[]
for item in df['PriceinUK']:
    PriceinUK+=[item.replace('£','').replace(',','')]
df['PriceinUK']=list(map(float,PriceinUK))

"""**Interpretation:**
From the above code, we are able to do some data preparation and data cleaning.
Here, we removed the pound ,Rupees, Euro symbol . It got Replaced by Space using Replace method . astype method is used for the change type of column or variable . Here we change the datatype of column because for using replace method data type should be String


"""

df= df.rename(columns = {'Subtitle':'KWH'})

"""**Interpretation:** Rename is method which used to change the column name according to user need .Here we change the name of column Subtitle in KWH it is denote Kilowatt Hours

**Check values whether is null or not**
"""

car_dataset=df.copy()
car_dataset.isnull().sum()

"""**Interpretation:**
   A new object will be created with a copy of the calling object’s data and indices. Modifications to the data or indices of the copy will not be reflected in the original object.   
  Pandas Series.isnull() function detect missing values in the given series object. It return a boolean same-sized object indicating if the values are NA. Missing values gets mapped to True and non-missing value gets mapped to False
"""

car_dataset['PriceinIndia']=car_dataset['PriceinIndia'].fillna(car_dataset['PriceinIndia'].mean())
car_dataset['PriceinUK']=car_dataset['PriceinUK'].fillna(car_dataset['PriceinUK'].mean())
car_dataset['PriceinGermany']=car_dataset['PriceinGermany'].fillna(car_dataset['PriceinGermany'].mean())

"""**Interpretation:**
FILLNA: Sometimes csv file has null values, which are later displayed as NaN in Data Frame. Just like pandas dropna() method manage and remove Null values from a data frame, fillna() manages and let the user replace NaN values with some value of their own.

Mean():Pandas dataframe.mean() function return the mean of the values for the requested axis. If the method is applied on a pandas series object, then the method returns a scalar value which is the mean value of all the observations in the dataframe.

Mode():Python is very robust when it comes to statistics and working with a set of a large range of values. The statistics module has a very large number of functions to work with very large data-sets. The mode() function is one of such methods

Median():Median. Median is the middle value of the dataset i.e if we sort the data from smallest to biggest (or biggest to smallest) and then take the value in the middle of the set: that's the Median
"""

car_dataset.isnull().sum()

"""**Encoding the type of drive**"""

car_dataset.replace({'Drive':{'All Wheel Drive':1,'Front Wheel Drive':0,'Rear Wheel Drive':2}},inplace=True)
car_dataset['Drive']=list(map(float,car_dataset['Drive']))
df=car_dataset.copy()
car_dataset.head(170)

"""**Interpretation:**
Encoading:  strings are stored as Unicode, i.e. each character in the string is represented by a code point. So, each string is just a sequence of Unicode code points.
For efficient storage of these strings, the sequence of code points is converted into a set of bytes. The process is known as encoding.

**Type Of Drive**
"""

print(df.Drive.value_counts())

sns.countplot(x = 'Drive', data = df)

"""**Interpretation:**
the count of each type of drive for the vehicles.
There are three types of Drive

1.Front Wheel Drive - 0.0

2.All Wheel Drive - 1.0

3 Third Wheel Drive - 2.0

**Number of Seats**
"""

print(df.NumberofSeats.value_counts())

sns.countplot(x = 'NumberofSeats', data = df)

"""**Interpretation:**
the data distribution considering both, the number of seats 
There are 2,4,5,6,7,9 number of seats . In this no 5 is high typed data
"""

plt.figure(figsize=(8,6))
sns.countplot(x = 'NumberofSeats', hue='Drive', data=df)

"""**Interpretation:**
the data distribution considering both, the number of seats and type of drive.
"""

plt.figure(figsize=(18,10))
sns.countplot(y = 'Acceleration', data = df)

"""**Relation Between the column**"""

plt.figure(figsize=(8,8))
sns.heatmap(car_dataset.corr(), annot=True)

"""**Interpretation:**
It is important to discover and quantify the degree to which variables in your dataset are dependent upon each other. This knowledge can help you better prepare your data to meet the expectations of machine learning algorithms, such as linear regression, whose performance will degrade with the presence of these interdependencies.

Heatmap is defined as a graphical representation of data using colors to visualize the value of the matrix.
"""

sns.relplot(x="KWH", y="Acceleration", height=6,hue="Drive",data=df)

"""**Interpretation:**
It is corelation between Acceleration and Drive
"""

sns.relplot(x="KWH", y="Acceleration", size="NumberofSeats", height=6,sizes=(15, 100),data=df)

"""**Interpretation:**
It isrelation between Acceleration and No of Seats
"""

sns.relplot(x="TopSpeed", y="Range",height=6, hue="Drive",data=df)

"""**Interpretation:**
This is co relation between range and drive and there is high data in All wheel drive to 200-400 range
"""

sns.relplot(x="FastChargeSpeed", y="Efficiency", height=6,data=df)

"""**Interpretation:**
it is graph between Efficiency and Fast Charge Speed
"""

X = df.drop(['Name','PriceinGermany','PriceinUK'],axis=1)
Y = df['PriceinIndia']
#car_dataset.to_csv("newev.csv")

"""**Interpretation:**
Dropna Method is used to delete the Column on the basis of name from Dataframe
"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, random_state=2)

"""## Linear Regression Model

**Interpretation:**Linear regression is a statistical method for modeling relationships between a dependent variable with a given set of independent variables.
"""

lin_reg_model = LinearRegression()

"""**Interpretation:**
 loading the linear regression model
"""

lin_reg_model.fit(X_train,Y_train)

"""**Interpretation:** returns a linear regression model of the responses y, fit to the data matrix X."""

pred = lin_reg_model.predict(X_test)
pred

"""**Interpretation:**It is used to given prediction of given data"""

lin_reg_model.score(X_test, Y_test)

training_data_prediction = lin_reg_model.predict(X_train)
training_data_prediction

error_score = metrics.r2_score(Y_train, training_data_prediction)
print("R squared Error : ", error_score)

"""**Interpretation:**R2 indicates the proportion of data points which lie within the line created by the regression equation. A higher value of R2 is desirable as it indicates better results. We can import r2_score from sklearn."""

plt.scatter(Y_train, training_data_prediction)
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.title(" Actual Prices vs Predicted Prices")
plt.show()

"""**Interpretation:**
Int the scatter point graph we can see the points are in one line and many points are collaging on each other which means out Actual price of the EV Vehicle and predicted values are almost same which is a good result.
"""

test_data_prediction = lin_reg_model.predict(X_test)

"""**Interpretation:**"""

error_score = metrics.r2_score(Y_test, test_data_prediction)
print("R squared Error : ", error_score)

"""**Interpretation:**We got 1.0 R Square value for linear and lesso model and for Random Forest mode we got 0.99 which means our dataset is a better fit for the model. """

plt.scatter(Y_test, test_data_prediction)
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.title(" Actual Prices vs Predicted Prices")
plt.show()

"""**Interpretation:**A scatter plots are a form of mathematical or graphic diagram that displays values for two variables for a collection of data using Coordinates. One and many variables can be presented if the points are coded."""